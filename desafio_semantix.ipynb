{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Desafio Semantix</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i><font color=red>Questões teóricas</font></i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Qual o objetivo do comando cache em Spark?</b>\n",
    "<p>Salva o estado atual de uma operação complexa realizada em um RDD, evitando assim ter que realizá-la novamente em utilizações posteriores.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>O mesmo código implementado em Spark é normalmente mais rápido que a implementação equivalente em MapReduce. Por quê? </b>\n",
    "<p>Porque o Spark faz todo o processamento em memória ao contrário do MapReduce.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Qual é a função do SparkContext?</b>\n",
    "<p>SparkContext é a conexão entre Spark e o cluster, sendo que sua função é calcular a melhor estratégia de distribuição do processo Spark no cluster. Função esta extremamente essencial quando se utiliza objetos como RDD, acumuladores e broadcast.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explique com suas palavras o que é Resilient Distributed Datasets (RDD).</b>\n",
    "<p>É uma coleção de objetos distruíbos, imutável e tolerante a falhas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explique o que o código Scala abaixo faz</b>\n",
    "<p><i>val textFile = sc.textFile(\"hdfs://...\")</i></p>\n",
    "<p><i>val counts = textFile.flatMap(line => line.split(\" \"))</i></p>\n",
    "<p><i>.map(word => (word, 1))</i></p>\n",
    "<p><i>.reduceByKey(_ + _)</i></p>\n",
    "<p><i>counts.saveAsTextFile(\"hdfs://...\")</i></p>\n",
    "<p></p>\n",
    "<p>Abre o arquivo texto do HDFS e transforma-o em um objeto RDD, sendo que em seguida pega o conteúdo de cada linha dentro do RDD e gera uma coleção de itens, separando cada palavra através do caractere espaço. Depois gera um mapeamento de chave e valor, onde chave é cada uma das palavras e valor é igual 1. Na seqüência agrupa  as chaves de mesmo valor, somando a quantidade de números 1 por chave. Por fim, escreve o resultado obtido em um arquivo no HDFS. Finalizando, esse código implementa um contador de palavras.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i><font color=red>Questões práticas</font></i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import date_format, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = '^(.+) (.+) (.+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(.+) (.+) (.+)\" (\\d{3}) (.+)'\n",
    "\n",
    "def parse_line(row):\n",
    "    \n",
    "    match = re.search(pattern1, row)\n",
    "    if match is None:\n",
    "        return None\n",
    "    \n",
    "    return Row(host = match.group(1), undef1 = match.group(2), undef2 = match.group(3),  \n",
    "                      timestamp = datetime.strptime(match.group(4), '%d/%b/%Y:%H:%M:%S %z'),\n",
    "                      method = match.group(5), url = match.group(6), protocol = match.group(7),\n",
    "                      code = int(match.group(8)), bytes  = match.group(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = sc.textFile('NASA_access_log_Jul95').map(parse_line)\n",
    "file2 = sc.textFile('NASA_access_log_Aug95').map(parse_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf = file1.union(file2) \\\n",
    "                .filter(lambda row: row is not None) \\\n",
    "                .toDF() \\\n",
    "                .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Número de hosts únicos.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137855"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf.select('host').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. O total de erros 404.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20727"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf.filter('code = 404').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. As 5 URLs que mais causaram erro 404.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|                host|                 url|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|ts8-1.westwood.ts...|/images/Nasa-logo...|   37|\n",
      "| nexus.mlckew.edu.au|/images/nasa-logo...|   34|\n",
      "|       203.13.168.24|/images/nasa-logo...|   25|\n",
      "|       203.13.168.17|/images/nasa-logo...|   25|\n",
      "|        crl5.crl.com|/images/nasa-logo...|   22|\n",
      "+--------------------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "psdf.select('host', 'url') \\\n",
    "      .filter('code = 404') \\\n",
    "      .groupBy('host', 'url') \\\n",
    "      .count() \\\n",
    "      .orderBy('count', ascending=False) \\\n",
    "      .limit(5) \\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4. Quantidade de erros 404 por dia.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|count|\n",
      "+----------+-----+\n",
      "|1995/07/01|  302|\n",
      "|1995/07/02|  276|\n",
      "|1995/07/03|  464|\n",
      "|1995/07/04|  367|\n",
      "|1995/07/05|  472|\n",
      "|1995/07/06|  651|\n",
      "|1995/07/07|  577|\n",
      "|1995/07/08|  317|\n",
      "|1995/07/09|  342|\n",
      "|1995/07/10|  376|\n",
      "|1995/07/11|  490|\n",
      "|1995/07/12|  461|\n",
      "|1995/07/13|  531|\n",
      "|1995/07/14|  412|\n",
      "|1995/07/15|  251|\n",
      "|1995/07/16|  237|\n",
      "|1995/07/17|  419|\n",
      "|1995/07/18|  465|\n",
      "|1995/07/19|  644|\n",
      "|1995/07/20|  418|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "psdf.select(date_format('timestamp','yyyy/MM/dd').alias('date')) \\\n",
    "      .filter('code = 404') \\\n",
    "      .groupBy(\"date\") \\\n",
    "      .count() \\\n",
    "      .orderBy(\"date\") \\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. O total de bytes retornados.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum        |\n",
      "+-----------+\n",
      "|65408685976|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "psdf.select(sum('bytes').cast('long').alias('sum')).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
